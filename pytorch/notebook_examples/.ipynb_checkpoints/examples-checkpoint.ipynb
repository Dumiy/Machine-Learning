{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from models.neuralnet import NeuralNet\n",
    "from models.convnet import ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv1d', 'conv2d', 'conv3d', 'conv1dt', 'conv2dt', 'conv3dt'])\n",
      "torch.Size([1, 50, 49, 49])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Types of convolution available\n",
    "\n",
    "from models.utils import return_conv_dict_keys\n",
    "print(return_conv_dict_keys())\n",
    "# How to create ConvNets\n",
    "model = ConvNet(3, [['conv2d', '15,3,2'],\n",
    "                    ['conv2dt', '35,3,2'],\n",
    "                    ['conv2dt', '55,3,2'],\n",
    "                    ['conv2d', '50,3,2']],\n",
    "                     [[nn.MaxPool2d((2,2)),nn.BatchNorm2d(15),nn.ReLU()],\n",
    "                      'skip', nn.ReLU(),\n",
    "                      nn.ReLU()])\n",
    "print(model(torch.randn(1,3,100,100)).shape)\n",
    "\n",
    "model = ConvNet(3, \n",
    "                    [['conv2d', 'out_channels=15,kernel_size=3,stride=2'],\n",
    "                    ['conv2dt', 'out_channels=30,kernel_size=3,stride=2'],\n",
    "                    ['conv2dt', 'out_channels=50,kernel_size=3,stride=2'],\n",
    "                    ['conv2d', 'out_channels=55,kernel_size=3,stride=2,padding=(2,2)']],\n",
    "                    [[nn.MaxPool2d((2,2)),nn.BatchNorm2d(15),nn.ReLU()],\n",
    "                     'skip', \n",
    "                     nn.ReLU(),\n",
    "                     nn.ReLU()])\n",
    "model(torch.randn(1,3,100,100)).shape == (1,55,51,51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNet(100, [[15,True],\n",
    "                        [20,False], \n",
    "                        2],\n",
    "              [[torch.nn.ReLU(), torch.nn.BatchNorm1d(15)],\n",
    "               [torch.nn.ReLU(), torch.nn.BatchNorm1d(20)],\n",
    "               torch.nn.Sigmoid()])\n",
    "model(torch.randn(4,100)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for training ConvNet and NeuralNet to predict cat or dog  \n",
    "\n",
    "Using ImageClass for image and test accuracy function, any function can be custom written on any dataset or task  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils import ImageClass,train,test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "landmark = pd.read_csv(\"date.csv\")\n",
    "base_folder = 'ob_tur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0800 (37).jpg</td>\n",
       "      <td>rasnov_citadel/0800 (37).jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0800 (28).jpg</td>\n",
       "      <td>rasnov_citadel/0800 (28).jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0800 (34).jpg</td>\n",
       "      <td>rasnov_citadel/0800 (34).jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0800 (94).jpg</td>\n",
       "      <td>rasnov_citadel/0800 (94).jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0800 (79).jpg</td>\n",
       "      <td>rasnov_citadel/0800 (79).jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                    image_path  label\n",
       "0  0800 (37).jpg  rasnov_citadel/0800 (37).jpg      0\n",
       "1  0800 (28).jpg  rasnov_citadel/0800 (28).jpg      0\n",
       "2  0800 (34).jpg  rasnov_citadel/0800 (34).jpg      0\n",
       "3  0800 (94).jpg  rasnov_citadel/0800 (94).jpg      0\n",
       "4  0800 (79).jpg  rasnov_citadel/0800 (79).jpg      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "dataset = os.listdir(\"train\")\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog.6841.jpg',\n",
       " 'cat.7288.jpg',\n",
       " 'dog.2738.jpg',\n",
       " 'dog.10090.jpg',\n",
       " 'cat.6148.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "for x in dataset:\n",
    "    if 'cat' in x:\n",
    "        label_list.append(0)\n",
    "    else:\n",
    "        label_list.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(dataset,label_list,random_state=1,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating dataset with labels and spliting for train and testing we are gonna define preprocessing steps to do on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fd26f36730>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.Resize((250,250)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.4,0.4,0.4),(0.1,0.1,0.1))\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(ImageClass(x_train,y_train,preprocessing,\"train\"),batch_size=16)\n",
    "test_loader = DataLoader(ImageClass(x_test,y_test,preprocessing,\"train\"),batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(landmark['image_path'].tolist(),landmark['label'].tolist(),random_state=1,test_size=0.3)\n",
    "bianca_loader = DataLoader(ImageClass(x_train,y_train,preprocessing,base_folder),batch_size=16,shuffle=True)\n",
    "biancatest_loader = DataLoader(ImageClass(x_test,y_test,preprocessing,base_folder),batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(3, [['conv2d', 'out_channels=50,kernel_size=15,stride=2'],\n",
    "                    ['conv2d', 'out_channels=100,kernel_size=7,stride=2'],\n",
    "                    ['conv2d', 'out_channels=150,kernel_size=3,stride=1'],\n",
    "                    ['conv2d', 'out_channels=100,kernel_size=3,stride=1']],\n",
    "                    [[nn.MaxPool2d((2,3)),nn.BatchNorm2d(50),nn.ReLU()],\n",
    "                     [nn.MaxPool2d((2,2)),nn.BatchNorm2d(100),nn.ReLU()], \n",
    "                     [nn.MaxPool2d((2,2)),nn.BatchNorm2d(150),nn.ReLU()],\n",
    "                     [nn.ReLU(),nn.Flatten()]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    out_shape = model(torch.randn((1,3,250,250),requires_grad=False)).shape[1]\n",
    "model.train()\n",
    "print(out_shape)\n",
    "model2 = NeuralNet(out_shape, [528,500,9],\n",
    "              [torch.nn.ReLU(),torch.nn.ReLU(),\"skip\"])\n",
    "models = [model,model2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.custom import CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_preprocess(x):\n",
    "    return torch.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = CustomModel(models,prediction_preprocess).cuda()\n",
    "optim = torch.optim.Adam(final_model.parameters(),lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim,step_size=12,gamma=0.1)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,final_model,test_loader):\n",
    "    correct = 0 \n",
    "    final_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            output = final_model(x.cuda())\n",
    "            correct+=(torch.argmax(output,dim=1) == y.cuda()).item()\n",
    "        print(\"Epoch {} - Accuracy - {:.2f}%\".format(epoch,(correct /len(test_loader))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 Length 35 \tLoss: 2.193600\n",
      "Epoch 0 - Accuracy - 21.19%\n",
      "Train Epoch: 1 Length 35 \tLoss: 2.136061\n",
      "Epoch 1 - Accuracy - 33.90%\n",
      "Train Epoch: 2 Length 35 \tLoss: 1.839989\n",
      "Epoch 2 - Accuracy - 37.29%\n",
      "Train Epoch: 3 Length 35 \tLoss: 1.778563\n",
      "Epoch 3 - Accuracy - 44.92%\n",
      "Train Epoch: 4 Length 35 \tLoss: 2.069886\n",
      "Epoch 4 - Accuracy - 54.24%\n",
      "Train Epoch: 5 Length 35 \tLoss: 1.498630\n",
      "Epoch 5 - Accuracy - 56.36%\n",
      "Train Epoch: 6 Length 35 \tLoss: 1.712986\n",
      "Epoch 6 - Accuracy - 59.75%\n",
      "Train Epoch: 7 Length 35 \tLoss: 1.536920\n",
      "Epoch 7 - Accuracy - 60.59%\n",
      "Train Epoch: 8 Length 35 \tLoss: 1.398962\n",
      "Epoch 8 - Accuracy - 63.56%\n",
      "Train Epoch: 9 Length 35 \tLoss: 1.427579\n",
      "Epoch 9 - Accuracy - 61.86%\n",
      "Train Epoch: 10 Length 35 \tLoss: 1.550839\n",
      "Epoch 10 - Accuracy - 65.25%\n",
      "Train Epoch: 11 Length 35 \tLoss: 1.376087\n",
      "Epoch 11 - Accuracy - 65.25%\n",
      "Train Epoch: 12 Length 35 \tLoss: 1.378455\n",
      "Epoch 12 - Accuracy - 66.10%\n",
      "Train Epoch: 13 Length 35 \tLoss: 1.450982\n",
      "Epoch 13 - Accuracy - 66.95%\n",
      "Train Epoch: 14 Length 35 \tLoss: 1.377738\n",
      "Epoch 14 - Accuracy - 66.10%\n",
      "Train Epoch: 15 Length 35 \tLoss: 1.378418\n",
      "Epoch 15 - Accuracy - 66.10%\n",
      "Train Epoch: 16 Length 35 \tLoss: 1.373750\n",
      "Epoch 16 - Accuracy - 66.95%\n",
      "Train Epoch: 17 Length 35 \tLoss: 1.375106\n",
      "Epoch 17 - Accuracy - 67.80%\n",
      "Train Epoch: 18 Length 35 \tLoss: 1.385653\n",
      "Epoch 18 - Accuracy - 66.53%\n",
      "Train Epoch: 19 Length 35 \tLoss: 1.424500\n",
      "Epoch 19 - Accuracy - 66.95%\n",
      "Train Epoch: 20 Length 35 \tLoss: 1.558417\n",
      "Epoch 20 - Accuracy - 65.68%\n",
      "Train Epoch: 21 Length 35 \tLoss: 1.379072\n",
      "Epoch 21 - Accuracy - 65.68%\n",
      "Train Epoch: 22 Length 35 \tLoss: 1.374865\n",
      "Epoch 22 - Accuracy - 66.95%\n",
      "Train Epoch: 23 Length 35 \tLoss: 1.373677\n",
      "Epoch 23 - Accuracy - 64.41%\n",
      "Train Epoch: 24 Length 35 \tLoss: 1.377180\n",
      "Epoch 24 - Accuracy - 65.68%\n",
      "Train Epoch: 25 Length 35 \tLoss: 1.372881\n",
      "Epoch 25 - Accuracy - 65.25%\n",
      "Train Epoch: 26 Length 35 \tLoss: 1.375466\n",
      "Epoch 26 - Accuracy - 66.10%\n",
      "Train Epoch: 27 Length 35 \tLoss: 1.381625\n",
      "Epoch 27 - Accuracy - 66.53%\n",
      "Train Epoch: 28 Length 35 \tLoss: 1.375997\n",
      "Epoch 28 - Accuracy - 65.25%\n",
      "Train Epoch: 29 Length 35 \tLoss: 1.691637\n",
      "Epoch 29 - Accuracy - 65.25%\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(30):\n",
    "    train(epochs,final_model,optim,bianca_loader,loss)\n",
    "    scheduler.step()\n",
    "    test(epochs,final_model,biancatest_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5909"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878666666666667"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " correct /len(test_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
